---
title: Can an autonomous vehicle be racist?
category: Algorithm Bias
author: Karthik Hosur
tags: ["#AI", "#Algorithm"]
date: 2021-05-23
thumbnail: image.jpeg
featured: true
---
## Can an autonomous vehicle be racist?

Recent mainstream news reports suggested that autonomous cars are unlikely to detect pedestrians crossing the road if they have dark skin and thus run them over.
The academic paper, “Predictive Inequity in Object Detection,” by a group of researchers at the Georgia Institute of Technology, highlighted the matter with a series of experiments testing different deep learning computer vision models, such as the Faster R-CNN model and R-50-FPN, on images of pedestrians with different skin tones. The study described how the researchers enlisted the help of human classifiers to look through the collection of roughly 3,500 images, and assign labels as either “LS” for light skin or “DS” for dark skin, and then trained the neural network model using this data set. There was an attempt to ensure the manual classification process was not tainted by any cultural biases.
The group found that their models found it difficult to detect people with dark skin, which led them to the conclusion: “This study provides compelling evidence of the real problem that may arise if this source of capture bias is not considered before deploying these sort of recognition models.
How do build standards and hold computers accountable for its Bais?